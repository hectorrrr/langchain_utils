{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <div style= \"font-family: Cambria; font-weight:bold; letter-spacing: 0px; color:white; font-size:180%; text-align:left;padding:3.0px; background: maroon; border-bottom: 8px solid black\" > TABLE OF CONTENTS<br><div>\n",
    "* [IMPORTS](#1)\n",
    "* [Introduction](#2)\n",
    "* [GraphQA Chain](#3)\n",
    "* [Custom Chain](#4)\n",
    "* [Semantic Retrieval](#5)\n",
    "* [Final Chain](#6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import langchain\n",
    "## Chains\n",
    "from operator import itemgetter\n",
    "\n",
    "from langchain_community.graphs import Neo4jGraph\n",
    "\n",
    "from langchain_core.runnables import RunnableLambda, RunnablePassthrough\n",
    "\n",
    "from langchain_community.chains.graph_qa.prompts import (\n",
    "    CYPHER_QA_PROMPT,\n",
    "    CYPHER_GENERATION_PROMPT\n",
    ")\n",
    "## LLMs:\n",
    "from langchain_openai import OpenAI, ChatOpenAI\n",
    "\n",
    "langchain.debug=False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"2\"></a>\n",
    "# <div style= \"font-family: Cambria; font-weight:bold; letter-spacing: 0px; color: white; font-size:120%; text-align:left;padding:3.0px; background: maroon; border-bottom: 8px solid black\" > Introduction<br><div>\n",
    "\n",
    "In this notebook we are going to show how to create a 'Custom' GraphRAG set up, using as an example the GraphQAChain client provided by Langchain."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"3\"></a>\n",
    "# <div style= \"font-family: Cambria; font-weight:bold; letter-spacing: 0px; color: white; font-size:120%; text-align:left;padding:3.0px; background: maroon; border-bottom: 8px solid black\" > GraphQA Chain<br><div>\n",
    "\n",
    "We have based this development in the [GraphCypherQAChain](https://api.python.langchain.com/en/latest/chains/langchain_community.chains.graph_qa.cypher.GraphCypherQAChain.html) chain. We are going to show how to replicate it's main behaviour here, but adapting it to the LCEL langchain notation, considering that those old chains are deprecated. In this way we ensure that our final solution will be more 'production ready', and also will be more customized.\n",
    "\n",
    "\n",
    "Inspecting the chain class definition we realized that, by default, it uses two predefined prompts:\n",
    "\n",
    "* Query generation prompt: Handles the conversion from a user query to a CYPHER query\n",
    "\n",
    "* QuestionAnswer prompt: Once the context has been retrieved from our Knowledge graph, this prompt handles the conversation\n",
    "\n",
    "Let's take a look to this prompts:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['question', 'schema'], template='Task:Generate Cypher statement to query a graph database.\\nInstructions:\\nUse only the provided relationship types and properties in the schema.\\nDo not use any other relationship types or properties that are not provided.\\nSchema:\\n{schema}\\nNote: Do not include any explanations or apologies in your responses.\\nDo not respond to any questions that might ask anything else than for you to construct a Cypher statement.\\nDo not include any text except the generated Cypher statement.\\n\\nThe question is:\\n{question}')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CYPHER_GENERATION_PROMPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Task:Generate Cypher statement to query a graph database.\\nInstructions:\\nUse only the provided relationship types and properties in the schema.\\nDo not use any other relationship types or properties that are not provided.\\nSchema:\\nThis will be the schema of the graph\\nNote: Do not include any explanations or apologies in your responses.\\nDo not respond to any questions that might ask anything else than for you to construct a Cypher statement.\\nDo not include any text except the generated Cypher statement.\\n\\nThe question is:\\nHow to build a confusion matrix with plotly?'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CYPHER_GENERATION_PROMPT.invoke({'question':\"How to build a confusion matrix with plotly?\",'schema':'This will be the schema of the graph'}).text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['context', 'question'], template=\"You are an assistant that helps to form nice and human understandable answers.\\nThe information part contains the provided information that you must use to construct an answer.\\nThe provided information is authoritative, you must never doubt it or try to use your internal knowledge to correct it.\\nMake the answer sound as a response to the question. Do not mention that you based the result on the given information.\\nHere is an example:\\n\\nQuestion: Which managers own Neo4j stocks?\\nContext:[manager:CTL LLC, manager:JANE STREET GROUP LLC]\\nHelpful Answer: CTL LLC, JANE STREET GROUP LLC owns Neo4j stocks.\\n\\nFollow this example when generating answers.\\nIf the provided information is empty, say that you don't know the answer.\\nInformation:\\n{context}\\n\\nQuestion: {question}\\nHelpful Answer:\")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CYPHER_QA_PROMPT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, this second prompt is just to handle the conversation, once the query has retrieved some content, so we will focus in the first one.\n",
    "\n",
    "<a id=\"4\"></a>\n",
    "# <div style= \"font-family: Cambria; font-weight:bold; letter-spacing: 0px; color: white; font-size:120%; text-align:left;padding:3.0px; background: maroon; border-bottom: 8px solid black\" > Custom Chain<br><div>\n",
    "\n",
    "We are going to replicate here a chain that has mainly the same behaviour, but adapted to our use case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm=ChatOpenAI(temperature=0, model_name=\"gpt-3.5-turbo\") # gpt-4-0125-preview occasionally has issues\n",
    "\n",
    "chain = CYPHER_GENERATION_PROMPT | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = chain.invoke({'question':\"How to build a confusion matrix with plotly?\",'schema':'This will be the schema of the graph'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'MATCH (a:Actual)-[r:ACTUAL_PREDICTED]->(p:Predicted)\\nWITH {label: a.label, prediction: p.label} as data, count(*) as count\\nRETURN data, count'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see this value makes not sense at all, because we have not provided the schema to the LLM yet, let's reproduce this part based in the reference Chain\n",
    "\n",
    "### Load a graph from neo4j\n",
    "\n",
    "We do this with the wrapper that langchain community offers. We could create our own, but for now we will just stick to it.\n",
    "The main advantage of this client is that directly create an schema for us, so we can contextualize the LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = Neo4jGraph(url=\"bolt://localhost:7687\", username=\"neo4j\", password=os.environ['NEO4J_PASSWORD'],database='graphrag')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This function allows us to directly get the schema from the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.get_schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'node_props': {'Function': [{'property': 'description', 'type': 'STRING'},\n",
       "   {'property': 'embedding', 'type': 'LIST'},\n",
       "   {'property': 'name', 'type': 'STRING'},\n",
       "   {'property': 'code', 'type': 'STRING'},\n",
       "   {'property': 'file_path', 'type': 'STRING'}],\n",
       "  'Area': [{'property': 'name', 'type': 'STRING'}],\n",
       "  'SubArea': [{'property': 'name', 'type': 'STRING'}],\n",
       "  'Framework': [{'property': 'name', 'type': 'STRING'}],\n",
       "  'Class': [{'property': 'description', 'type': 'STRING'},\n",
       "   {'property': 'name', 'type': 'STRING'},\n",
       "   {'property': 'code', 'type': 'STRING'},\n",
       "   {'property': 'file_path', 'type': 'STRING'}]},\n",
       " 'rel_props': {},\n",
       " 'relationships': [{'start': 'Area',\n",
       "   'type': 'CONTAINS_SUBAREA',\n",
       "   'end': 'SubArea'},\n",
       "  {'start': 'Area', 'type': 'CONTAINS_FRAMEWORK', 'end': 'Framework'},\n",
       "  {'start': 'SubArea', 'type': 'CONTAINS_FRAMEWORK', 'end': 'Framework'},\n",
       "  {'start': 'Framework', 'type': 'CONTAINS_FUNCTION', 'end': 'Function'},\n",
       "  {'start': 'Framework', 'type': 'CONTAINS_CLASS', 'end': 'Class'}],\n",
       " 'metadata': {'constraint': [], 'index': []}}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.get_structured_schema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Invoke the function with this schema as input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = chain.invoke({'question':\"How to use plotly framework?\",'schema':graph.get_schema})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'MATCH (a:Area)-[:CONTAINS_FRAMEWORK]->(f:Framework {name: \"plotly\"})\\nRETURN f, a'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other advantage of the langchain graph client is that allows to directly run the queries returned by this first LLM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "context = graph.query(result.content)[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'f': {'name': 'plotly'}, 'a': {'name': 'visualization'}}]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here we added the keyword 'framework' in the question, but that is hightly unlikely in a normal query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"MATCH (a:Area)-[:CONTAINS_SUBAREA]->(sa:SubArea)-[:CONTAINS_FRAMEWORK]->(f:Framework)-[:CONTAINS_FUNCTION]->(func:Function)\\nWHERE func.name = 'plotly'\\nRETURN a, sa, f, func;\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = chain.invoke({'question':\"How to use plotly?\",'schema':graph.get_schema})\n",
    "\n",
    "result.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context = graph.query(result.content)[:5]\n",
    "context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first problem that we see is that considering how our graph is built, the entities are difficult to assign only by their name. This is a generic problem of this kind of solution. Entities should have a very descriptive name (Person, Organization...) so they can be eassily identified by a general LLM. So we should try and contextualize better about the entities that the LLM can expect. For that we will take as reference the base prompt used in the GraphCypherChain and add the following lines defining the entities for our problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You are a helpful assistant that understands the context of data science and can generate Cypher queries to retrieve information from a Neo4j database.\n",
    "\n",
    "The database schema includes the following entities:\n",
    "- Data Preprocessing Area: Nodes labeled as 'DataPreprocessingArea' representing areas of data preprocessing.\n",
    "- SubArea: Nodes labeled as 'SubArea' representing sub-areas within data preprocessing.\n",
    "- Framework: Nodes labeled as 'Framework' representing frameworks used in data science.\n",
    "- Class: Nodes labeled as 'Class' representing a set of functions defining a Python class within a framework.\n",
    "- Function: Nodes labeled as 'Function' representing specific functions within frameworks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompts:\n",
    "from langchain_core.prompts import (\n",
    "    PromptTemplate\n",
    ")\n",
    "\n",
    "cypher_gen_prompt = PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    You are a Cypher language expert.\n",
    "    Your Task:Generate Cypher statement to query a graph database.\n",
    "    To better contextualize, the Graph database is mapping the Data Science implementations using python\n",
    "    and is divided in the following entities:\n",
    "\n",
    "    Instructions:\n",
    "    Use only the provided relationship types and properties in the schema.\n",
    "    Do not use any other relationship types or properties that are not provided.\n",
    "    Schema:\n",
    "    {schema}\n",
    "    Note: Do not include any explanations or apologies in your responses.\n",
    "    Do not respond to any questions that might ask anything else than for you to construct a Cypher statement.\n",
    "    Do not include any text except the generated Cypher statement.\n",
    "        - Data Preprocessing Area: Nodes labeled as 'Area' representing areas of Data Science, like 'Data Visualization' or 'Data Preprocessing'.\n",
    "        - SubArea: Nodes labeled as 'SubArea' representing sub-areas within data preprocessing. This field is optional, some of the nodes may not have a relation with a 'SubArea' node, so generally \n",
    "        should not be added in the query.\n",
    "        - Framework: Nodes labeled as 'Framework' representing frameworks used in data science.\n",
    "        - Class: Nodes labeled as 'Class' representing a set of functions defining a Python class within a framework.\n",
    "        - Function: Nodes labeled as 'Function' representing custom functions built on top of those frameworks.\n",
    "    Nodes do not neccesarily have parents of each type of label.\n",
    "\n",
    "    Your main focus should be to identify the Framework and the Function that is being asked.\n",
    "    The question is:\n",
    "    {question}\n",
    "    \"\"\"\n",
    "   \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm=ChatOpenAI(temperature=0, model_name=\"gpt-3.5-turbo\") # gpt-4-0125-preview occasionally has issues\n",
    "\n",
    "custom_prompt_chain = cypher_gen_prompt | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = custom_prompt_chain.invoke({'question':\"How to use plotly?\",'schema':graph.get_schema})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'MATCH (:Framework{name: \"plotly\"})-[:CONTAINS_FUNCTION]->(f:Function)\\nRETURN f;'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'MATCH (:Framework{name: \"plotly\"})-[:CONTAINS_FUNCTION]->(:Function{name: \"generate_confusion_matrix\"})\\nRETURN *;'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "result = custom_prompt_chain.invoke({'question':\"How to use plotly to generate a confusion matrix?\",'schema':graph.get_schema})\n",
    "result.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Generated Cypher Statement is not valid\n{code: Neo.ClientError.Statement.SyntaxError} {message: RETURN * is not allowed when there are no variables in scope (line 2, column 1 (offset: 104))\r\n\"RETURN *;\"\r\n ^}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mCypherSyntaxError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\hecto\\OneDrive\\Escritorio\\github_projects\\langchain_utils\\langchain_env\\lib\\site-packages\\langchain_community\\graphs\\neo4j_graph.py:419\u001b[0m, in \u001b[0;36mNeo4jGraph.query\u001b[1;34m(self, query, params)\u001b[0m\n\u001b[0;32m    418\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 419\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mQuery\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    420\u001b[0m     json_data \u001b[38;5;241m=\u001b[39m [r\u001b[38;5;241m.\u001b[39mdata() \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m data]\n",
      "File \u001b[1;32mc:\\Users\\hecto\\OneDrive\\Escritorio\\github_projects\\langchain_utils\\langchain_env\\lib\\site-packages\\neo4j\\_sync\\work\\session.py:314\u001b[0m, in \u001b[0;36mSession.run\u001b[1;34m(self, query, parameters, **kwargs)\u001b[0m\n\u001b[0;32m    313\u001b[0m parameters \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(parameters \u001b[38;5;129;01mor\u001b[39;00m {}, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m--> 314\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_auto_result\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    315\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdatabase\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    316\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimpersonated_user\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdefault_access_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    317\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbookmarks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnotifications_min_severity\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    318\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnotifications_disabled_classifications\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    319\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    321\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_auto_result\n",
      "File \u001b[1;32mc:\\Users\\hecto\\OneDrive\\Escritorio\\github_projects\\langchain_utils\\langchain_env\\lib\\site-packages\\neo4j\\_sync\\work\\result.py:221\u001b[0m, in \u001b[0;36mResult._run\u001b[1;34m(self, query, parameters, db, imp_user, access_mode, bookmarks, notifications_min_severity, notifications_disabled_classifications)\u001b[0m\n\u001b[0;32m    220\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connection\u001b[38;5;241m.\u001b[39msend_all()\n\u001b[1;32m--> 221\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_attach\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\hecto\\OneDrive\\Escritorio\\github_projects\\langchain_utils\\langchain_env\\lib\\site-packages\\neo4j\\_sync\\work\\result.py:409\u001b[0m, in \u001b[0;36mResult._attach\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    408\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_attached \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[1;32m--> 409\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_connection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch_message\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\hecto\\OneDrive\\Escritorio\\github_projects\\langchain_utils\\langchain_env\\lib\\site-packages\\neo4j\\_sync\\io\\_common.py:178\u001b[0m, in \u001b[0;36mConnectionErrorHandler.__getattr__.<locals>.outer.<locals>.inner\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    177\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 178\u001b[0m     func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    179\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (Neo4jError, ServiceUnavailable, SessionExpired) \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[1;32mc:\\Users\\hecto\\OneDrive\\Escritorio\\github_projects\\langchain_utils\\langchain_env\\lib\\site-packages\\neo4j\\_sync\\io\\_bolt.py:860\u001b[0m, in \u001b[0;36mBolt.fetch_message\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    857\u001b[0m tag, fields \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minbox\u001b[38;5;241m.\u001b[39mpop(\n\u001b[0;32m    858\u001b[0m     hydration_hooks\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresponses[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mhydration_hooks\n\u001b[0;32m    859\u001b[0m )\n\u001b[1;32m--> 860\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_process_message\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtag\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfields\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    861\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39midle_since \u001b[38;5;241m=\u001b[39m monotonic()\n",
      "File \u001b[1;32mc:\\Users\\hecto\\OneDrive\\Escritorio\\github_projects\\langchain_utils\\langchain_env\\lib\\site-packages\\neo4j\\_sync\\io\\_bolt5.py:370\u001b[0m, in \u001b[0;36mBolt5x0._process_message\u001b[1;34m(self, tag, fields)\u001b[0m\n\u001b[0;32m    369\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 370\u001b[0m     \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mon_failure\u001b[49m\u001b[43m(\u001b[49m\u001b[43msummary_metadata\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    371\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ServiceUnavailable, DatabaseUnavailable):\n",
      "File \u001b[1;32mc:\\Users\\hecto\\OneDrive\\Escritorio\\github_projects\\langchain_utils\\langchain_env\\lib\\site-packages\\neo4j\\_sync\\io\\_common.py:245\u001b[0m, in \u001b[0;36mResponse.on_failure\u001b[1;34m(self, metadata)\u001b[0m\n\u001b[0;32m    244\u001b[0m Util\u001b[38;5;241m.\u001b[39mcallback(handler)\n\u001b[1;32m--> 245\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m Neo4jError\u001b[38;5;241m.\u001b[39mhydrate(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmetadata)\n",
      "\u001b[1;31mCypherSyntaxError\u001b[0m: {code: Neo.ClientError.Statement.SyntaxError} {message: RETURN * is not allowed when there are no variables in scope (line 2, column 1 (offset: 104))\r\n\"RETURN *;\"\r\n ^}",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m context \u001b[38;5;241m=\u001b[39m \u001b[43mgraph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquery\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontent\u001b[49m\u001b[43m)\u001b[49m[:\u001b[38;5;241m5\u001b[39m]\n\u001b[0;32m      2\u001b[0m context\n",
      "File \u001b[1;32mc:\\Users\\hecto\\OneDrive\\Escritorio\\github_projects\\langchain_utils\\langchain_env\\lib\\site-packages\\langchain_community\\graphs\\neo4j_graph.py:425\u001b[0m, in \u001b[0;36mNeo4jGraph.query\u001b[1;34m(self, query, params)\u001b[0m\n\u001b[0;32m    423\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m json_data\n\u001b[0;32m    424\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m CypherSyntaxError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m--> 425\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGenerated Cypher Statement is not valid\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: Generated Cypher Statement is not valid\n{code: Neo.ClientError.Statement.SyntaxError} {message: RETURN * is not allowed when there are no variables in scope (line 2, column 1 (offset: 104))\r\n\"RETURN *;\"\r\n ^}"
     ]
    }
   ],
   "source": [
    "context = graph.query(result.content)[:5]\n",
    "context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"MATCH (a:Area)-[:CONTAINS_FRAMEWORK]->(f:Framework)-[:CONTAINS_FUNCTION]->(func:Function)\\nWHERE f.name = 'plotly' AND func.name = 'plot_confusion_matrix'\\nRETURN func.code\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 48, 'prompt_tokens': 477, 'total_tokens': 525}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-06f7b36a-04ba-4b7c-a7da-27ba12d48e27-0', usage_metadata={'input_tokens': 477, 'output_tokens': 48, 'total_tokens': 525})"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "result = custom_prompt_chain.invoke({'question':\"How to use plotly to generate a 'plot_confusion_matrix' function? Provide the code\",'schema':graph.get_schema})\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'func.code': 'def plot_confusion_matrix(confusion_matrix, class_names):     \"\"\"     Generates a confusion matrix plot from a sklearn confusion matrix object.      Parameters:     - confusion_matrix (array): Numpy array containing the confusion matrix information.     - class_names (list of str): List of class names corresponding to the labels.      Returns:     - fig (plotly.graph_objects.Figure): The Plotly figure object for the confusion matrix plot.     \"\"\"     fig = ff.create_annotated_heatmap(         z=confusion_matrix,         x=class_names,         y=class_names,         colorscale=\\'Blues\\',         showscale=True     )     fig.update_layout(title=\\'Confusion Matrix\\', xaxis_title=\\'Predicted Label\\', yaxis_title=\\'True Label\\')     fig.update_traces(text=confusion_matrix.astype(str), texttemplate=\\'%{text}\\')     return fig'}]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context = graph.query(result.content)[:5]\n",
    "context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We can see that after contextualizing what can be understood as a 'Framework' in our graph, the LLM is correctly identifying plotly as a framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_prompt_template =  PromptTemplate.from_template(\n",
    "    \"\"\"You are an assistant that helps to form nice and human understandable answers.\n",
    "    The information part contains the provided information that you must use to construct an answer.\n",
    "    The provided information is authoritative, you must never doubt it or try to use your internal knowledge to correct it.\n",
    "    Make the answer sound as a response to the question. Do not mention that you based the result on the given information.\n",
    "    If the provided information is empty, say that you don't know the answer.\n",
    "    Information:\n",
    "    {context}\n",
    "    \n",
    "    Question: {question}\n",
    "    Helpful Answer:\n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have sligthly adapted the prompt from the reference chain to our end, removing the example mainly. Let's build the complete chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_cypher_query(query):\n",
    "    print(\"Generated query---->\",query.content)\n",
    "    node_contents = graph.query(query.content)[:5]\n",
    "    return node_contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"question\": \"How to use plotly to generate a 'plot_confusion_matrix' function? Provide the code\",\n",
      "  \"schema\": \"Node properties:\\nFunction {description: STRING, embedding: LIST, name: STRING, code: STRING, file_path: STRING}\\nArea {name: STRING}\\nSubArea {name: STRING}\\nFramework {name: STRING}\\nClass {description: STRING, name: STRING, code: STRING, file_path: STRING}\\nRelationship properties:\\n\\nThe relationships:\\n(:Area)-[:CONTAINS_SUBAREA]->(:SubArea)\\n(:Area)-[:CONTAINS_FRAMEWORK]->(:Framework)\\n(:SubArea)-[:CONTAINS_FRAMEWORK]->(:Framework)\\n(:Framework)-[:CONTAINS_FUNCTION]->(:Function)\\n(:Framework)-[:CONTAINS_CLASS]->(:Class)\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<context,question>] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"question\": \"How to use plotly to generate a 'plot_confusion_matrix' function? Provide the code\",\n",
      "  \"schema\": \"Node properties:\\nFunction {description: STRING, embedding: LIST, name: STRING, code: STRING, file_path: STRING}\\nArea {name: STRING}\\nSubArea {name: STRING}\\nFramework {name: STRING}\\nClass {description: STRING, name: STRING, code: STRING, file_path: STRING}\\nRelationship properties:\\n\\nThe relationships:\\n(:Area)-[:CONTAINS_SUBAREA]->(:SubArea)\\n(:Area)-[:CONTAINS_FRAMEWORK]->(:Framework)\\n(:SubArea)-[:CONTAINS_FRAMEWORK]->(:Framework)\\n(:Framework)-[:CONTAINS_FUNCTION]->(:Function)\\n(:Framework)-[:CONTAINS_CLASS]->(:Class)\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<context,question> > chain:RunnablePassthrough] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"question\": \"How to use plotly to generate a 'plot_confusion_matrix' function? Provide the code\",\n",
      "  \"schema\": \"Node properties:\\nFunction {description: STRING, embedding: LIST, name: STRING, code: STRING, file_path: STRING}\\nArea {name: STRING}\\nSubArea {name: STRING}\\nFramework {name: STRING}\\nClass {description: STRING, name: STRING, code: STRING, file_path: STRING}\\nRelationship properties:\\n\\nThe relationships:\\n(:Area)-[:CONTAINS_SUBAREA]->(:SubArea)\\n(:Area)-[:CONTAINS_FRAMEWORK]->(:Framework)\\n(:SubArea)-[:CONTAINS_FRAMEWORK]->(:Framework)\\n(:Framework)-[:CONTAINS_FUNCTION]->(:Function)\\n(:Framework)-[:CONTAINS_CLASS]->(:Class)\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<context,question> > chain:RunnablePassthrough] [0ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"question\": \"How to use plotly to generate a 'plot_confusion_matrix' function? Provide the code\",\n",
      "  \"schema\": \"Node properties:\\nFunction {description: STRING, embedding: LIST, name: STRING, code: STRING, file_path: STRING}\\nArea {name: STRING}\\nSubArea {name: STRING}\\nFramework {name: STRING}\\nClass {description: STRING, name: STRING, code: STRING, file_path: STRING}\\nRelationship properties:\\n\\nThe relationships:\\n(:Area)-[:CONTAINS_SUBAREA]->(:SubArea)\\n(:Area)-[:CONTAINS_FRAMEWORK]->(:Framework)\\n(:SubArea)-[:CONTAINS_FRAMEWORK]->(:Framework)\\n(:Framework)-[:CONTAINS_FUNCTION]->(:Function)\\n(:Framework)-[:CONTAINS_CLASS]->(:Class)\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<context,question> > chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"question\": \"How to use plotly to generate a 'plot_confusion_matrix' function? Provide the code\",\n",
      "  \"schema\": \"Node properties:\\nFunction {description: STRING, embedding: LIST, name: STRING, code: STRING, file_path: STRING}\\nArea {name: STRING}\\nSubArea {name: STRING}\\nFramework {name: STRING}\\nClass {description: STRING, name: STRING, code: STRING, file_path: STRING}\\nRelationship properties:\\n\\nThe relationships:\\n(:Area)-[:CONTAINS_SUBAREA]->(:SubArea)\\n(:Area)-[:CONTAINS_FRAMEWORK]->(:Framework)\\n(:SubArea)-[:CONTAINS_FRAMEWORK]->(:Framework)\\n(:Framework)-[:CONTAINS_FUNCTION]->(:Function)\\n(:Framework)-[:CONTAINS_CLASS]->(:Class)\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<context,question> > chain:RunnableSequence > prompt:PromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m{\n",
      "  \"question\": \"How to use plotly to generate a 'plot_confusion_matrix' function? Provide the code\",\n",
      "  \"schema\": \"Node properties:\\nFunction {description: STRING, embedding: LIST, name: STRING, code: STRING, file_path: STRING}\\nArea {name: STRING}\\nSubArea {name: STRING}\\nFramework {name: STRING}\\nClass {description: STRING, name: STRING, code: STRING, file_path: STRING}\\nRelationship properties:\\n\\nThe relationships:\\n(:Area)-[:CONTAINS_SUBAREA]->(:SubArea)\\n(:Area)-[:CONTAINS_FRAMEWORK]->(:Framework)\\n(:SubArea)-[:CONTAINS_FRAMEWORK]->(:Framework)\\n(:Framework)-[:CONTAINS_FUNCTION]->(:Function)\\n(:Framework)-[:CONTAINS_CLASS]->(:Class)\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<context,question> > chain:RunnableSequence > prompt:PromptTemplate] [1ms] Exiting Prompt run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<context,question> > chain:RunnableSequence > llm:ChatOpenAI] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: \\n    You are a Cypher language expert.\\n    Your Task:Generate Cypher statement to query a graph database.\\n    To better contextualize, the Graph database is mapping the Data Science implementations using python\\n    and is divided in the following entities:\\n\\n    Instructions:\\n    Use only the provided relationship types and properties in the schema.\\n    Do not use any other relationship types or properties that are not provided.\\n    Schema:\\n    Node properties:\\nFunction {description: STRING, embedding: LIST, name: STRING, code: STRING, file_path: STRING}\\nArea {name: STRING}\\nSubArea {name: STRING}\\nFramework {name: STRING}\\nClass {description: STRING, name: STRING, code: STRING, file_path: STRING}\\nRelationship properties:\\n\\nThe relationships:\\n(:Area)-[:CONTAINS_SUBAREA]->(:SubArea)\\n(:Area)-[:CONTAINS_FRAMEWORK]->(:Framework)\\n(:SubArea)-[:CONTAINS_FRAMEWORK]->(:Framework)\\n(:Framework)-[:CONTAINS_FUNCTION]->(:Function)\\n(:Framework)-[:CONTAINS_CLASS]->(:Class)\\n    Note: Do not include any explanations or apologies in your responses.\\n    Do not respond to any questions that might ask anything else than for you to construct a Cypher statement.\\n    Do not include any text except the generated Cypher statement.\\n        - Data Preprocessing Area: Nodes labeled as 'Area' representing areas of Data Science, like 'Data Visualization' or 'Data Preprocessing'.\\n        - SubArea: Nodes labeled as 'SubArea' representing sub-areas within data preprocessing. This field is optional, some of the nodes may not have a relation with a 'SubArea' node, so generally \\n        should not be added in the query.\\n        - Framework: Nodes labeled as 'Framework' representing frameworks used in data science.\\n        - Class: Nodes labeled as 'Class' representing a set of functions defining a Python class within a framework.\\n        - Function: Nodes labeled as 'Function' representing custom functions built on top of those frameworks.\\n    Nodes do not neccesarily have parents of each type of label.\\n\\n    Your main focus should be to identify the Framework and the Function that is being asked.\\n    The question is:\\n    How to use plotly to generate a 'plot_confusion_matrix' function? Provide the code\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<context,question> > chain:RunnableSequence > llm:ChatOpenAI] [1.07s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"MATCH (a:Area)-[:CONTAINS_FRAMEWORK]->(f:Framework)-[:CONTAINS_FUNCTION]->(func:Function)\\nWHERE f.name = 'plotly' AND func.name = 'plot_confusion_matrix'\\nRETURN func.code\",\n",
      "        \"generation_info\": {\n",
      "          \"finish_reason\": \"stop\",\n",
      "          \"logprobs\": null\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"MATCH (a:Area)-[:CONTAINS_FRAMEWORK]->(f:Framework)-[:CONTAINS_FUNCTION]->(func:Function)\\nWHERE f.name = 'plotly' AND func.name = 'plot_confusion_matrix'\\nRETURN func.code\",\n",
      "            \"additional_kwargs\": {\n",
      "              \"refusal\": null\n",
      "            },\n",
      "            \"response_metadata\": {\n",
      "              \"token_usage\": {\n",
      "                \"completion_tokens\": 48,\n",
      "                \"prompt_tokens\": 477,\n",
      "                \"total_tokens\": 525\n",
      "              },\n",
      "              \"model_name\": \"gpt-3.5-turbo-0125\",\n",
      "              \"system_fingerprint\": null,\n",
      "              \"finish_reason\": \"stop\",\n",
      "              \"logprobs\": null\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-a978063f-ad67-4c26-8480-93911d5c36ba-0\",\n",
      "            \"usage_metadata\": {\n",
      "              \"input_tokens\": 477,\n",
      "              \"output_tokens\": 48,\n",
      "              \"total_tokens\": 525\n",
      "            },\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": {\n",
      "    \"token_usage\": {\n",
      "      \"completion_tokens\": 48,\n",
      "      \"prompt_tokens\": 477,\n",
      "      \"total_tokens\": 525\n",
      "    },\n",
      "    \"model_name\": \"gpt-3.5-turbo-0125\",\n",
      "    \"system_fingerprint\": null\n",
      "  },\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<context,question> > chain:RunnableSequence > chain:run_cypher_query] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "Generated query----> MATCH (a:Area)-[:CONTAINS_FRAMEWORK]->(f:Framework)-[:CONTAINS_FUNCTION]->(func:Function)\n",
      "WHERE f.name = 'plotly' AND func.name = 'plot_confusion_matrix'\n",
      "RETURN func.code\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<context,question> > chain:RunnableSequence > chain:run_cypher_query] [3ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": [\n",
      "    {\n",
      "      \"func.code\": \"def plot_confusion_matrix(confusion_matrix, class_names):     \\\"\\\"\\\"     Generates a confusion matrix plot from a sklearn confusion matrix object.      Parameters:     - confusion_matrix (array): Numpy array containing the confusion matrix information.     - class_names (list of str): List of class names corresponding to the labels.      Returns:     - fig (plotly.graph_objects.Figure): The Plotly figure object for the confusion matrix plot.     \\\"\\\"\\\"     fig = ff.create_annotated_heatmap(         z=confusion_matrix,         x=class_names,         y=class_names,         colorscale='Blues',         showscale=True     )     fig.update_layout(title='Confusion Matrix', xaxis_title='Predicted Label', yaxis_title='True Label')     fig.update_traces(text=confusion_matrix.astype(str), texttemplate='%{text}')     return fig\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<context,question> > chain:RunnableSequence] [1.08s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": [\n",
      "    {\n",
      "      \"func.code\": \"def plot_confusion_matrix(confusion_matrix, class_names):     \\\"\\\"\\\"     Generates a confusion matrix plot from a sklearn confusion matrix object.      Parameters:     - confusion_matrix (array): Numpy array containing the confusion matrix information.     - class_names (list of str): List of class names corresponding to the labels.      Returns:     - fig (plotly.graph_objects.Figure): The Plotly figure object for the confusion matrix plot.     \\\"\\\"\\\"     fig = ff.create_annotated_heatmap(         z=confusion_matrix,         x=class_names,         y=class_names,         colorscale='Blues',         showscale=True     )     fig.update_layout(title='Confusion Matrix', xaxis_title='Predicted Label', yaxis_title='True Label')     fig.update_traces(text=confusion_matrix.astype(str), texttemplate='%{text}')     return fig\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<context,question>] [1.09s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"context\": [\n",
      "    {\n",
      "      \"func.code\": \"def plot_confusion_matrix(confusion_matrix, class_names):     \\\"\\\"\\\"     Generates a confusion matrix plot from a sklearn confusion matrix object.      Parameters:     - confusion_matrix (array): Numpy array containing the confusion matrix information.     - class_names (list of str): List of class names corresponding to the labels.      Returns:     - fig (plotly.graph_objects.Figure): The Plotly figure object for the confusion matrix plot.     \\\"\\\"\\\"     fig = ff.create_annotated_heatmap(         z=confusion_matrix,         x=class_names,         y=class_names,         colorscale='Blues',         showscale=True     )     fig.update_layout(title='Confusion Matrix', xaxis_title='Predicted Label', yaxis_title='True Label')     fig.update_traces(text=confusion_matrix.astype(str), texttemplate='%{text}')     return fig\"\n",
      "    }\n",
      "  ],\n",
      "  \"question\": {\n",
      "    \"question\": \"How to use plotly to generate a 'plot_confusion_matrix' function? Provide the code\",\n",
      "    \"schema\": \"Node properties:\\nFunction {description: STRING, embedding: LIST, name: STRING, code: STRING, file_path: STRING}\\nArea {name: STRING}\\nSubArea {name: STRING}\\nFramework {name: STRING}\\nClass {description: STRING, name: STRING, code: STRING, file_path: STRING}\\nRelationship properties:\\n\\nThe relationships:\\n(:Area)-[:CONTAINS_SUBAREA]->(:SubArea)\\n(:Area)-[:CONTAINS_FRAMEWORK]->(:Framework)\\n(:SubArea)-[:CONTAINS_FRAMEWORK]->(:Framework)\\n(:Framework)-[:CONTAINS_FUNCTION]->(:Function)\\n(:Framework)-[:CONTAINS_CLASS]->(:Class)\"\n",
      "  }\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > prompt:PromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m{\n",
      "  \"context\": [\n",
      "    {\n",
      "      \"func.code\": \"def plot_confusion_matrix(confusion_matrix, class_names):     \\\"\\\"\\\"     Generates a confusion matrix plot from a sklearn confusion matrix object.      Parameters:     - confusion_matrix (array): Numpy array containing the confusion matrix information.     - class_names (list of str): List of class names corresponding to the labels.      Returns:     - fig (plotly.graph_objects.Figure): The Plotly figure object for the confusion matrix plot.     \\\"\\\"\\\"     fig = ff.create_annotated_heatmap(         z=confusion_matrix,         x=class_names,         y=class_names,         colorscale='Blues',         showscale=True     )     fig.update_layout(title='Confusion Matrix', xaxis_title='Predicted Label', yaxis_title='True Label')     fig.update_traces(text=confusion_matrix.astype(str), texttemplate='%{text}')     return fig\"\n",
      "    }\n",
      "  ],\n",
      "  \"question\": {\n",
      "    \"question\": \"How to use plotly to generate a 'plot_confusion_matrix' function? Provide the code\",\n",
      "    \"schema\": \"Node properties:\\nFunction {description: STRING, embedding: LIST, name: STRING, code: STRING, file_path: STRING}\\nArea {name: STRING}\\nSubArea {name: STRING}\\nFramework {name: STRING}\\nClass {description: STRING, name: STRING, code: STRING, file_path: STRING}\\nRelationship properties:\\n\\nThe relationships:\\n(:Area)-[:CONTAINS_SUBAREA]->(:SubArea)\\n(:Area)-[:CONTAINS_FRAMEWORK]->(:Framework)\\n(:SubArea)-[:CONTAINS_FRAMEWORK]->(:Framework)\\n(:Framework)-[:CONTAINS_FUNCTION]->(:Function)\\n(:Framework)-[:CONTAINS_CLASS]->(:Class)\"\n",
      "  }\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > prompt:PromptTemplate] [1ms] Exiting Prompt run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:RunnableSequence > llm:ChatOpenAI] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: You are an assistant that helps to form nice and human understandable answers.\\n    The information part contains the provided information that you must use to construct an answer.\\n    The provided information is authoritative, you must never doubt it or try to use your internal knowledge to correct it.\\n    Make the answer sound as a response to the question. Do not mention that you based the result on the given information.\\n    If the provided information is empty, say that you don't know the answer.\\n    Information:\\n    [{'func.code': 'def plot_confusion_matrix(confusion_matrix, class_names):     \\\"\\\"\\\"     Generates a confusion matrix plot from a sklearn confusion matrix object.      Parameters:     - confusion_matrix (array): Numpy array containing the confusion matrix information.     - class_names (list of str): List of class names corresponding to the labels.      Returns:     - fig (plotly.graph_objects.Figure): The Plotly figure object for the confusion matrix plot.     \\\"\\\"\\\"     fig = ff.create_annotated_heatmap(         z=confusion_matrix,         x=class_names,         y=class_names,         colorscale=\\\\'Blues\\\\',         showscale=True     )     fig.update_layout(title=\\\\'Confusion Matrix\\\\', xaxis_title=\\\\'Predicted Label\\\\', yaxis_title=\\\\'True Label\\\\')     fig.update_traces(text=confusion_matrix.astype(str), texttemplate=\\\\'%{text}\\\\')     return fig'}]\\n    \\n    Question: {'question': \\\"How to use plotly to generate a 'plot_confusion_matrix' function? Provide the code\\\", 'schema': 'Node properties:\\\\nFunction {description: STRING, embedding: LIST, name: STRING, code: STRING, file_path: STRING}\\\\nArea {name: STRING}\\\\nSubArea {name: STRING}\\\\nFramework {name: STRING}\\\\nClass {description: STRING, name: STRING, code: STRING, file_path: STRING}\\\\nRelationship properties:\\\\n\\\\nThe relationships:\\\\n(:Area)-[:CONTAINS_SUBAREA]->(:SubArea)\\\\n(:Area)-[:CONTAINS_FRAMEWORK]->(:Framework)\\\\n(:SubArea)-[:CONTAINS_FRAMEWORK]->(:Framework)\\\\n(:Framework)-[:CONTAINS_FUNCTION]->(:Function)\\\\n(:Framework)-[:CONTAINS_CLASS]->(:Class)'}\\n    Helpful Answer:\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:RunnableSequence > llm:ChatOpenAI] [1.91s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"To generate a 'plot_confusion_matrix' function using plotly, you can use the following code:\\n\\n```python\\ndef plot_confusion_matrix(confusion_matrix, class_names):\\n    fig = ff.create_annotated_heatmap(\\n        z=confusion_matrix,\\n        x=class_names,\\n        y=class_names,\\n        colorscale='Blues',\\n        showscale=True\\n    )\\n    fig.update_layout(title='Confusion Matrix', xaxis_title='Predicted Label', yaxis_title='True Label')\\n    fig.update_traces(text=confusion_matrix.astype(str), texttemplate='%{text}')\\n    return fig\\n```\\n\\nThis code will generate a confusion matrix plot using the provided sklearn confusion matrix object and class names.\",\n",
      "        \"generation_info\": {\n",
      "          \"finish_reason\": \"stop\",\n",
      "          \"logprobs\": null\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"To generate a 'plot_confusion_matrix' function using plotly, you can use the following code:\\n\\n```python\\ndef plot_confusion_matrix(confusion_matrix, class_names):\\n    fig = ff.create_annotated_heatmap(\\n        z=confusion_matrix,\\n        x=class_names,\\n        y=class_names,\\n        colorscale='Blues',\\n        showscale=True\\n    )\\n    fig.update_layout(title='Confusion Matrix', xaxis_title='Predicted Label', yaxis_title='True Label')\\n    fig.update_traces(text=confusion_matrix.astype(str), texttemplate='%{text}')\\n    return fig\\n```\\n\\nThis code will generate a confusion matrix plot using the provided sklearn confusion matrix object and class names.\",\n",
      "            \"additional_kwargs\": {\n",
      "              \"refusal\": null\n",
      "            },\n",
      "            \"response_metadata\": {\n",
      "              \"token_usage\": {\n",
      "                \"completion_tokens\": 149,\n",
      "                \"prompt_tokens\": 479,\n",
      "                \"total_tokens\": 628\n",
      "              },\n",
      "              \"model_name\": \"gpt-3.5-turbo-0125\",\n",
      "              \"system_fingerprint\": null,\n",
      "              \"finish_reason\": \"stop\",\n",
      "              \"logprobs\": null\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-430d6c36-9970-42f7-8339-a33508187fbd-0\",\n",
      "            \"usage_metadata\": {\n",
      "              \"input_tokens\": 479,\n",
      "              \"output_tokens\": 149,\n",
      "              \"total_tokens\": 628\n",
      "            },\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": {\n",
      "    \"token_usage\": {\n",
      "      \"completion_tokens\": 149,\n",
      "      \"prompt_tokens\": 479,\n",
      "      \"total_tokens\": 628\n",
      "    },\n",
      "    \"model_name\": \"gpt-3.5-turbo-0125\",\n",
      "    \"system_fingerprint\": null\n",
      "  },\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence] [3.00s] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"To generate a 'plot_confusion_matrix' function using plotly, you can use the following code:\\n\\n```python\\ndef plot_confusion_matrix(confusion_matrix, class_names):\\n    fig = ff.create_annotated_heatmap(\\n        z=confusion_matrix,\\n        x=class_names,\\n        y=class_names,\\n        colorscale='Blues',\\n        showscale=True\\n    )\\n    fig.update_layout(title='Confusion Matrix', xaxis_title='Predicted Label', yaxis_title='True Label')\\n    fig.update_traces(text=confusion_matrix.astype(str), texttemplate='%{text}')\\n    return fig\\n```\\n\\nThis code will generate a confusion matrix plot using the provided sklearn confusion matrix object and class names.\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 149, 'prompt_tokens': 479, 'total_tokens': 628}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-430d6c36-9970-42f7-8339-a33508187fbd-0', usage_metadata={'input_tokens': 479, 'output_tokens': 149, 'total_tokens': 628})"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_qa_chain = {'context': cypher_gen_prompt | llm | RunnableLambda(run_cypher_query), 'question': RunnablePassthrough()} | qa_prompt_template | llm\n",
    "\n",
    "langchain.debug=True\n",
    "\n",
    "full_qa_chain.invoke({'question':\"How to use plotly to generate a 'plot_confusion_matrix' function? Provide the code\",'schema':graph.get_schema})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This was everything regarding the usage of the Graph based in a query retrieval strategy. But seing that this is not always accurate and may not give any result, we are going to mix it with a 'Semantic simmilarity' retrieval procedure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
